{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0508bc31",
   "metadata": {},
   "source": [
    "# Чтение и обработка словарей из pdf\n",
    "\n",
    "Использован модуль PyPDFLoader для чтения pdf, затем обработан текст на выделение слова с ударением и по возможности его одной словоформы в отдельный словарь.\n",
    "\n",
    "## Обработка словаря Новый орфоэпический словарь русского языка для всех, кто хочет быть грамотным/ Т.А. Гридина, Н.И. Коновалова, В.В. Бурцева. — Москва: АСТ, 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a98c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a323d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Gridina_T._Noviy_orfoepicheskiy_slovar_russkogo_yazika.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbc5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первый раунд чистки\n",
    "words = []\n",
    "for page in pages[13:638]:\n",
    "    content = page.page_content.replace(' /accent', '+').replace('фaccent', '+').replace('/accent', '+')\n",
    "    content = content.replace(' /box2', '').replace('/box2', '')\n",
    "    content = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", content)\n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        if ';' in line:\n",
    "            word = line.split(';')[0]\n",
    "            \n",
    "            word = re.sub('[0-9]+', '', word)\n",
    "            words.append( ''.join(word.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3ff009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['абажу+р', 'абажу+ра', 'аббревиату+ра', 'аббревиату+ры', 'абза+ц']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#второй раунд чистки\n",
    "bad_items = ['.', '...', ']', ':', ')']\n",
    "new = []\n",
    "for word in words:\n",
    "    splt = word.split(',')\n",
    "    for i in splt:\n",
    "        index = i.count('+')\n",
    "        if index == 1:\n",
    "            if not any(x in i for x in bad_items):\n",
    "                new.append(i)\n",
    "new[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6a5c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['абаж+ур', 'абаж+ура', 'аббревиат+ура', 'аббревиат+уры', 'абз+ац']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим слова, которые не по алфавиту и ошибочны\n",
    "\n",
    "fin_list = []\n",
    "for i in new:\n",
    "    index = new.index(i)\n",
    "    \n",
    "    if (index !=0) and (index != len(new) - 1):\n",
    "        previous = index - 1\n",
    "        next_element = index +1\n",
    "        if (new[index][0] == new[previous][0]) or (new[index][0] == new[next_element][0]):\n",
    "            accent_index = i.find('+')\n",
    "            i = i[:accent_index-1]+ '+' + i[accent_index-1] + i[accent_index+1:]\n",
    "            fin_list.append(i)\n",
    "\n",
    "    else:\n",
    "        accent_index = i.find('+')\n",
    "        i = i[:accent_index-1]+ '+' + i[accent_index-1] + i[accent_index+1:]\n",
    "        fin_list.append(i)\n",
    "fin_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e1c967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>with_accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>абажур</td>\n",
       "      <td>абаж+ур</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>абажура</td>\n",
       "      <td>абаж+ура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>аббревиатура</td>\n",
       "      <td>аббревиат+ура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>аббревиатуры</td>\n",
       "      <td>аббревиат+уры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абзац</td>\n",
       "      <td>абз+ац</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       raw_text    with_accent\n",
       "0        абажур        абаж+ур\n",
       "1       абажура       абаж+ура\n",
       "2  аббревиатура  аббревиат+ура\n",
       "3  аббревиатуры  аббревиат+уры\n",
       "4         абзац         абз+ац"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(fin_list, columns = ['with_accent'])\n",
    "df['raw_text'] = df['with_accent'].apply(lambda x: re.sub('[^а-яёА-ЯЁ]+', '', x))\n",
    "df = df[['raw_text', 'with_accent']]\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d311fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dict1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcff0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "ru_nlp = spacy.load('ru_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea9f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3088"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_lst = list(df['raw_text'])\n",
    "lemmas_dict = {}\n",
    "for item in raw_lst:\n",
    "    lemma = ru_nlp(item)[0].lemma_\n",
    "    lemmas_dict[lemma] = lemmas_dict.get(lemma, 0) + 1\n",
    "    \n",
    "len(lemmas_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b8809",
   "metadata": {},
   "source": [
    "Итого было выгружено 4 746 слов, с уникальной леммой - 3088\n",
    "\n",
    "## Обработка Орфоэпический словарь русского языка: правильно ли мы говорим? / О. А. Михайлова. — Москва : Издательство АСТ, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be429804",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = PyPDFLoader(\"Mihaylova_O._Orfoepicheskiy_slovar_russkogo_yazika.pdf\")\n",
    "pages2 = loader2.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d5d148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агресси́вный', 'агре́ссия', 'агроно́мия', 'ада́птер', 'адеква́тный']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for page in pages2[10:157]:\n",
    "    content = page.page_content.split('\\n')\n",
    "    for line in content:\n",
    "        if ',' in line:\n",
    "            words.append(line.split(',')[0].strip())\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03a63cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агресси́вный', 'агре́ссия', 'агроно́мия', 'ада́птер', 'адеква́тный']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#второй раунд чистки\n",
    "bad_items = ['.', '...', ']', ':', ')', '(', '`']\n",
    "new = []\n",
    "for word in words:\n",
    "     if not any(x in word for x in bad_items):\n",
    "            if word != '':\n",
    "                new.append(word.strip())\n",
    "new[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d7e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агресси́вный', 'агре́ссия', 'агроно́мия', 'ада́птер', 'адеква́тный']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#удалим слова, которые не по алфавиту и ошибочны\n",
    "\n",
    "fin_list = []\n",
    "for i in new:\n",
    "    index = new.index(i)\n",
    "    \n",
    "    if (index !=0) and (index != len(new) - 1):\n",
    "        previous = index - 1\n",
    "        next_element = index +1\n",
    "        if (new[index][0] == new[previous][0]) or (new[index][0] == new[next_element][0]):\n",
    "            #accent_index = i.find('+')\n",
    "            #i = i[:accent_index-1]+ '+' + i[accent_index-1] + i[accent_index+1:]\n",
    "            fin_list.append(i)\n",
    "\n",
    "    else:\n",
    "        #accent_index = i.find('+')\n",
    "        #i = i[:accent_index-1]+ '+' + i[accent_index-1] + i[accent_index+1:]\n",
    "        fin_list.append(i)\n",
    "fin_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a3fb67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ала: ['ала́', 'а́ла']\",\n",
       " \"баржам: ['баржа́м', 'ба́ржа']\",\n",
       " \"баржа: ['баржа́м', 'ба́ржа']\",\n",
       " \"батуд: ['бату́д', 'бату́т']\",\n",
       " \"батут: ['бату́д', 'бату́т']\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выделим в отдельный список те слова, которые имеют несколько вариантов ударений\n",
    "multiple_accents = []\n",
    "for i in fin_list:\n",
    "    if ' и ' in i:\n",
    "        lst = i.split(' и ')\n",
    "        for item in lst:\n",
    "            item = re.sub('[^а-яёА-ЯЁ+ ]+', '', item)\n",
    "            multiple_accents.append(f'{item}: {lst}')\n",
    "multiple_accents = list(dict.fromkeys(multiple_accents))\n",
    "multiple_accents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6afbc2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удалим слова, где есть пробелы\n",
    "fin = []\n",
    "for i in fin_list:\n",
    "    if ' ' not in i:\n",
    "        fin.append(i)\n",
    "len(fin)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6d8034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агресс+ивный', 'агр+ессия', 'агрон+омия', 'ад+аптер', 'адекв+атный']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#поставим вместо ударения знак +\n",
    "accented = ['а́', 'я́', 'у́', 'ю́', 'о́', 'е́', 'э́', 'и́', 'ы́', 'ё']\n",
    "\n",
    "fin_last = []\n",
    "\n",
    "for word in fin:\n",
    "    accent_index = [word.find(x) for x in accented if word.find(x) >= 0]\n",
    "    if len(accent_index) == 0:\n",
    "        fin_last.append(word)\n",
    "    elif len(accent_index) == 1:\n",
    "        word_new = word[:accent_index[0]]+'+'+word[accent_index[0]:]\n",
    "        word_new = re.sub('[^а-яёА-ЯЁ+]+', '', word_new)\n",
    "        fin_last.append(word_new)\n",
    "    else:\n",
    "        word_new = word[:accent_index[0]]+'+'+word[accent_index[0]:]\n",
    "        for i in range(1, len(accent_index)):\n",
    "            #word = test[:accent_index[0]]+'+'+test[accent_index[0]:]\n",
    "            word_new = word_new[:accent_index[i]+i]+'+'+word_new[accent_index[i]+i:]\n",
    "            word_new = re.sub('[^а-яёА-ЯЁ+]+', '', word_new)\n",
    "            fin_last.append(word_new)\n",
    "fin_last[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9f73b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>with_accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>агрессивный</td>\n",
       "      <td>агресс+ивный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>агрессия</td>\n",
       "      <td>агр+ессия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>агрономия</td>\n",
       "      <td>агрон+омия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>адаптер</td>\n",
       "      <td>ад+аптер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>адекватный</td>\n",
       "      <td>адекв+атный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      raw_text   with_accent\n",
       "0  агрессивный  агресс+ивный\n",
       "1     агрессия     агр+ессия\n",
       "2    агрономия    агрон+омия\n",
       "3      адаптер      ад+аптер\n",
       "4   адекватный   адекв+атный"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(fin_last, columns = ['with_accent'])\n",
    "df['raw_text'] = df['with_accent'].apply(lambda x: re.sub('[^а-яёА-ЯЁ]+', '', x))\n",
    "df = df[['raw_text', 'with_accent']]\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc125f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dict2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7283ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4539"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_lst = list(df['raw_text'])\n",
    "lemmas_dict = {}\n",
    "for item in raw_lst:\n",
    "    lemma = ru_nlp(item)[0].lemma_\n",
    "    lemmas_dict[lemma] = lemmas_dict.get(lemma, 0) + 1\n",
    "    \n",
    "len(lemmas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b11e3da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ала: ал+а, +ала',\n",
       " 'баржам: барж+ам, б+аржа',\n",
       " 'баржа: барж+ам, б+аржа',\n",
       " 'батуд: бат+уд, бат+ут',\n",
       " 'батут: бат+уд, бат+ут']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_acc = []\n",
    "\n",
    "for word in multiple_accents:\n",
    "    accent_index = [[m.start() for m in re.finditer(i, word)] for i in accented if len([m.start() for m in re.finditer(i, word)]) >= 0 ]\n",
    "    accent_index = [item for row in accent_index for item in row]\n",
    "    \n",
    "    if len(accent_index) == 0:\n",
    "        mult_acc.append(word)\n",
    "    elif len(accent_index) == 1:\n",
    "        word_new = word[:accent_index[0]]+'+'+word[accent_index[0]:]\n",
    "        word_new = re.sub('[^а-яёА-ЯЁ+:, ]+', '', word_new)\n",
    "        mult_acc.append(word_new)\n",
    "    else:\n",
    "        word_new = word[:accent_index[0]]+'+'+word[accent_index[0]:]\n",
    "        for i in range(1, len(accent_index)):\n",
    "            #word = test[:accent_index[0]]+'+'+test[accent_index[0]:]\n",
    "            word_new = word_new[:accent_index[i]+1]+'+'+word_new[accent_index[i]+1:]\n",
    "            word_new = re.sub('[^а-яёА-ЯЁ+:, ]+', '', word_new)\n",
    "            mult_acc.append(word_new)\n",
    "    \n",
    "mult_acc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mult_acc, columns = ['mult_accents'])\n",
    "df.to_csv('dict2_multiple_accents.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
